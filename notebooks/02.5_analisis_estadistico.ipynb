{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An√°lisis Estad√≠stico Profundo - Calidad de Servicio SERVQUAL\n",
    "## Fundaci√≥n Telet√≥n - Diagn√≥stico de √Åreas de Oportunidad\n",
    "\n",
    "Este notebook realiza un an√°lisis estad√≠stico riguroso para identificar:\n",
    "- **Drivers de satisfacci√≥n**: ¬øQu√© dimensiones SERVQUAL impactan m√°s el NPS?\n",
    "- **Diferencias significativas**: ¬øHay diferencias por tipo de organizaci√≥n, regi√≥n o antig√ºedad?\n",
    "- **Segmentos cr√≠ticos**: ¬øD√≥nde est√°n los benefactores insatisfechos?\n",
    "- **√Åreas de oportunidad**: Recomendaciones basadas en evidencia estad√≠stica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency, ttest_ind, f_oneway, pearsonr, spearmanr\n",
    "from scipy.stats import shapiro, levene\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuraci√≥n visual\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"Librer√≠as cargadas correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos enriquecidos\n",
    "df = pd.read_csv('../data/teleton_enriched.csv', encoding='utf-8-sig')\n",
    "print(f\"Dataset: {df.shape[0]} registros x {df.shape[1]} columnas\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir variables\n",
    "vars_servqual = ['AT_1', 'AT_2', 'FI_1', 'FI_2', 'FI_3', 'R_1', 'R_2', 'R_3', 'E_1', 'E_2', 'E_3', 'E_4']\n",
    "vars_scores = ['score_tangibles', 'score_fiabilidad', 'score_responsiveness', 'score_empatia']\n",
    "vars_outcome = ['D_1', 'NPS', 'C_1', 'INFO']\n",
    "vars_categoricas = ['Giro', 'Puesto', 'region', 'antiguedad_grupo', 'nps_categoria', 'calidad_nivel']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. DIAGN√ìSTICO INICIAL - Visi√≥n del Analista\n",
    "\n",
    "## 1.1 M√©tricas Clave de Calidad de Servicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen ejecutivo de m√©tricas\n",
    "print(\"=\"*70)\n",
    "print(\"DIAGN√ìSTICO DE CALIDAD DE SERVICIO - FUNDACI√ìN TELET√ìN\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# NPS Score\n",
    "nps_counts = df['nps_categoria'].value_counts(normalize=True) * 100\n",
    "nps_score = nps_counts.get('Promotor', 0) - nps_counts.get('Detractor', 0)\n",
    "\n",
    "print(f\"\\nüìä M√âTRICAS GENERALES\")\n",
    "print(f\"   NPS Score: {nps_score:.1f}\")\n",
    "print(f\"   Satisfacci√≥n promedio: {df['D_1'].mean():.2f}/10\")\n",
    "print(f\"   Calidad percibida: {df['C_1'].mean():.2f}/5\")\n",
    "print(f\"   Score SERVQUAL total: {df['score_servqual_total'].mean():.2f}/5\")\n",
    "\n",
    "print(f\"\\nüìà DISTRIBUCI√ìN NPS\")\n",
    "print(f\"   Promotores (9-10): {nps_counts.get('Promotor', 0):.1f}%\")\n",
    "print(f\"   Pasivos (7-8): {nps_counts.get('Pasivo', 0):.1f}%\")\n",
    "print(f\"   Detractores (1-6): {nps_counts.get('Detractor', 0):.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scores por dimensi√≥n SERVQUAL\n",
    "print(\"\\nüìã SCORES POR DIMENSI√ìN SERVQUAL\")\n",
    "print(\"-\"*40)\n",
    "for score in vars_scores:\n",
    "    dim_name = score.replace('score_', '').upper()\n",
    "    mean_val = df[score].mean()\n",
    "    std_val = df[score].std()\n",
    "    status = \"‚úÖ\" if mean_val >= 4 else \"‚ö†Ô∏è\" if mean_val >= 3.5 else \"‚ùå\"\n",
    "    print(f\"   {dim_name:15s}: {mean_val:.2f} ¬± {std_val:.2f} {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Identificaci√≥n de Segmentos Cr√≠ticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar benefactores insatisfechos (Detractores)\n",
    "detractores = df[df['nps_categoria'] == 'Detractor']\n",
    "promotores = df[df['nps_categoria'] == 'Promotor']\n",
    "\n",
    "print(\"\\nüî¥ AN√ÅLISIS DE DETRACTORES (benefactores insatisfechos)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total detractores: {len(detractores)} ({len(detractores)/len(df)*100:.1f}%)\")\n",
    "\n",
    "if len(detractores) > 0:\n",
    "    print(f\"\\nPerfil de detractores:\")\n",
    "    print(f\"   Giro m√°s com√∫n: {detractores['Giro'].mode().values[0] if len(detractores['Giro'].mode()) > 0 else 'N/A'}\")\n",
    "    print(f\"   Regi√≥n m√°s com√∫n: {detractores['region'].mode().values[0] if len(detractores['region'].dropna().mode()) > 0 else 'N/A'}\")\n",
    "    print(f\"   Antig√ºedad promedio: {detractores['A√ëOS'].mean():.1f} a√±os\")\n",
    "    \n",
    "    print(f\"\\nScores SERVQUAL de detractores vs promotores:\")\n",
    "    for score in vars_scores:\n",
    "        det_mean = detractores[score].mean()\n",
    "        prom_mean = promotores[score].mean()\n",
    "        diff = prom_mean - det_mean\n",
    "        print(f\"   {score.replace('score_', ''):15s}: Detractores={det_mean:.2f}, Promotores={prom_mean:.2f} (gap={diff:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis por Giro - identificar segmentos problem√°ticos\n",
    "print(\"\\nüìä SATISFACCI√ìN POR TIPO DE ORGANIZACI√ìN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "giro_stats = df.groupby('Giro').agg({\n",
    "    'D_1': ['mean', 'std', 'count'],\n",
    "    'NPS': 'mean',\n",
    "    'score_servqual_total': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "giro_stats.columns = ['Satisfacci√≥n', 'Std', 'N', 'NPS', 'SERVQUAL']\n",
    "giro_stats = giro_stats.sort_values('Satisfacci√≥n', ascending=False)\n",
    "\n",
    "print(giro_stats.to_string())\n",
    "\n",
    "# Identificar giro con menor satisfacci√≥n\n",
    "giro_peor = giro_stats['Satisfacci√≥n'].idxmin()\n",
    "print(f\"\\n‚ö†Ô∏è √ÅREA DE OPORTUNIDAD: '{giro_peor}' tiene la menor satisfacci√≥n promedio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis por Regi√≥n\n",
    "print(\"\\nüìç SATISFACCI√ìN POR REGI√ìN GEOGR√ÅFICA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "region_stats = df.groupby('region').agg({\n",
    "    'D_1': ['mean', 'count'],\n",
    "    'NPS': 'mean',\n",
    "    'score_servqual_total': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "region_stats.columns = ['Satisfacci√≥n', 'N', 'NPS', 'SERVQUAL']\n",
    "region_stats = region_stats.sort_values('Satisfacci√≥n', ascending=False)\n",
    "\n",
    "print(region_stats.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. AN√ÅLISIS DE CORRELACIONES\n",
    "\n",
    "## 2.1 Correlaci√≥n de Pearson - Variables Num√©ricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlaci√≥n completa\n",
    "vars_numericas = vars_scores + vars_outcome + ['A√ëOS', 'score_servqual_total']\n",
    "corr_matrix = df[vars_numericas].corr()\n",
    "\n",
    "# Visualizaci√≥n\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='RdYlBu_r',\n",
    "            center=0, vmin=-1, vmax=1, ax=ax, square=True)\n",
    "ax.set_title('Matriz de Correlaciones - Variables Num√©ricas', fontweight='bold', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlaciones espec√≠ficas con NPS (variable objetivo)\n",
    "print(\"\\nüéØ CORRELACIONES CON NPS (variable objetivo)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "correlaciones_nps = []\n",
    "for var in vars_scores + ['D_1', 'C_1', 'INFO', 'A√ëOS']:\n",
    "    corr, p_value = pearsonr(df[var].dropna(), df.loc[df[var].notna(), 'NPS'])\n",
    "    sig = \"***\" if p_value < 0.001 else \"**\" if p_value < 0.01 else \"*\" if p_value < 0.05 else \"\"\n",
    "    correlaciones_nps.append({'Variable': var, 'Correlaci√≥n': corr, 'p-value': p_value, 'Sig': sig})\n",
    "\n",
    "corr_df = pd.DataFrame(correlaciones_nps).sort_values('Correlaci√≥n', ascending=False)\n",
    "print(corr_df.to_string(index=False))\n",
    "\n",
    "print(\"\\nNota: *** p<0.001, ** p<0.01, * p<0.05\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar correlaciones con NPS\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "corr_nps = df[vars_scores].corrwith(df['NPS']).sort_values(ascending=True)\n",
    "colors = ['#e74c3c' if x < 0.3 else '#f39c12' if x < 0.5 else '#27ae60' for x in corr_nps.values]\n",
    "\n",
    "bars = ax.barh([s.replace('score_', '').capitalize() for s in corr_nps.index], \n",
    "               corr_nps.values, color=colors)\n",
    "ax.axvline(x=0.3, color='orange', linestyle='--', alpha=0.7, label='Correlaci√≥n d√©bil')\n",
    "ax.axvline(x=0.5, color='green', linestyle='--', alpha=0.7, label='Correlaci√≥n moderada')\n",
    "\n",
    "for bar, val in zip(bars, corr_nps.values):\n",
    "    ax.text(val + 0.02, bar.get_y() + bar.get_height()/2, f'{val:.3f}', va='center', fontsize=11)\n",
    "\n",
    "ax.set_xlabel('Correlaci√≥n con NPS')\n",
    "ax.set_title('¬øQu√© dimensi√≥n SERVQUAL impacta m√°s el NPS?', fontweight='bold', fontsize=14)\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_xlim(0, 0.8)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "dim_mas_importante = corr_nps.idxmax().replace('score_', '').upper()\n",
    "print(f\"\\nüí° INSIGHT: La dimensi√≥n '{dim_mas_importante}' es la que m√°s impacta el NPS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. PRUEBAS DE HIP√ìTESIS\n",
    "\n",
    "## 3.1 Prueba Chi-Cuadrada - Asociaci√≥n entre Variables Categ√≥ricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_square_test(df, var1, var2):\n",
    "    \"\"\"Realiza prueba chi-cuadrada y retorna resultados\"\"\"\n",
    "    contingency = pd.crosstab(df[var1], df[var2])\n",
    "    chi2, p_value, dof, expected = chi2_contingency(contingency)\n",
    "    \n",
    "    # Cram√©r's V para tama√±o del efecto\n",
    "    n = contingency.sum().sum()\n",
    "    min_dim = min(contingency.shape) - 1\n",
    "    cramers_v = np.sqrt(chi2 / (n * min_dim)) if min_dim > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'chi2': chi2,\n",
    "        'p_value': p_value,\n",
    "        'dof': dof,\n",
    "        'cramers_v': cramers_v,\n",
    "        'significativo': p_value < 0.05\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-cuadrada: NPS_categoria vs Giro\n",
    "print(\"\\nüî¨ PRUEBA CHI-CUADRADA: NPS Categor√≠a vs Tipo de Organizaci√≥n\")\n",
    "print(\"=\"*70)\n",
    "print(\"H‚ÇÄ: No hay asociaci√≥n entre el tipo de organizaci√≥n y la categor√≠a NPS\")\n",
    "print(\"H‚ÇÅ: Existe asociaci√≥n entre el tipo de organizaci√≥n y la categor√≠a NPS\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "result = chi_square_test(df, 'nps_categoria', 'Giro')\n",
    "print(f\"\\nResultados:\")\n",
    "print(f\"   Chi¬≤ = {result['chi2']:.2f}\")\n",
    "print(f\"   Grados de libertad = {result['dof']}\")\n",
    "print(f\"   p-value = {result['p_value']:.4f}\")\n",
    "print(f\"   Cram√©r's V = {result['cramers_v']:.3f} (tama√±o del efecto)\")\n",
    "\n",
    "if result['significativo']:\n",
    "    print(f\"\\n‚úÖ CONCLUSI√ìN: Se RECHAZA H‚ÇÄ (p < 0.05)\")\n",
    "    print(f\"   Existe asociaci√≥n significativa entre el tipo de organizaci√≥n y el NPS.\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå CONCLUSI√ìN: NO se rechaza H‚ÇÄ (p >= 0.05)\")\n",
    "    print(f\"   No hay evidencia de asociaci√≥n entre tipo de organizaci√≥n y NPS.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabla de contingencia visual\n",
    "contingency = pd.crosstab(df['Giro'], df['nps_categoria'], normalize='index') * 100\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "contingency.plot(kind='barh', stacked=True, ax=ax, \n",
    "                 color=['#e74c3c', '#f39c12', '#27ae60'])\n",
    "ax.set_xlabel('Porcentaje')\n",
    "ax.set_title('Distribuci√≥n de NPS por Tipo de Organizaci√≥n', fontweight='bold')\n",
    "ax.legend(title='NPS Categor√≠a', bbox_to_anchor=(1.02, 1))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-cuadrada: NPS_categoria vs Antig√ºedad\n",
    "print(\"\\nüî¨ PRUEBA CHI-CUADRADA: NPS Categor√≠a vs Antig√ºedad del Benefactor\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "result2 = chi_square_test(df.dropna(subset=['antiguedad_grupo']), 'nps_categoria', 'antiguedad_grupo')\n",
    "print(f\"   Chi¬≤ = {result2['chi2']:.2f}, p-value = {result2['p_value']:.4f}\")\n",
    "print(f\"   {'‚úÖ Significativo' if result2['significativo'] else '‚ùå No significativo'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-cuadrada: NPS_categoria vs Regi√≥n\n",
    "print(\"\\nüî¨ PRUEBA CHI-CUADRADA: NPS Categor√≠a vs Regi√≥n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "df_region = df.dropna(subset=['region'])\n",
    "if len(df_region['region'].unique()) > 1:\n",
    "    result3 = chi_square_test(df_region, 'nps_categoria', 'region')\n",
    "    print(f\"   Chi¬≤ = {result3['chi2']:.2f}, p-value = {result3['p_value']:.4f}\")\n",
    "    print(f\"   {'‚úÖ Significativo' if result3['significativo'] else '‚ùå No significativo'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Prueba t de Student - Comparaci√≥n de Dos Grupos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_test_analysis(group1, group2, name1, name2, variable):\n",
    "    \"\"\"Realiza prueba t y retorna an√°lisis completo\"\"\"\n",
    "    # Prueba de normalidad (Shapiro-Wilk)\n",
    "    if len(group1) >= 3 and len(group2) >= 3:\n",
    "        _, p_norm1 = shapiro(group1[:50])  # Muestra para Shapiro\n",
    "        _, p_norm2 = shapiro(group2[:50])\n",
    "    else:\n",
    "        p_norm1, p_norm2 = 1, 1\n",
    "    \n",
    "    # Prueba de homogeneidad de varianzas (Levene)\n",
    "    _, p_levene = levene(group1, group2)\n",
    "    \n",
    "    # Prueba t (Welch si varianzas desiguales)\n",
    "    equal_var = p_levene > 0.05\n",
    "    t_stat, p_value = ttest_ind(group1, group2, equal_var=equal_var)\n",
    "    \n",
    "    # Tama√±o del efecto (Cohen's d)\n",
    "    pooled_std = np.sqrt(((len(group1)-1)*group1.std()**2 + (len(group2)-1)*group2.std()**2) / \n",
    "                         (len(group1)+len(group2)-2))\n",
    "    cohens_d = (group1.mean() - group2.mean()) / pooled_std if pooled_std > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        't_stat': t_stat,\n",
    "        'p_value': p_value,\n",
    "        'cohens_d': cohens_d,\n",
    "        'mean1': group1.mean(),\n",
    "        'mean2': group2.mean(),\n",
    "        'n1': len(group1),\n",
    "        'n2': len(group2),\n",
    "        'equal_var': equal_var\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prueba t: Empresas vs Educaci√≥n (los dos giros m√°s grandes)\n",
    "print(\"\\nüî¨ PRUEBA T: Satisfacci√≥n de Empresas vs Instituciones Educativas\")\n",
    "print(\"=\"*70)\n",
    "print(\"H‚ÇÄ: Œº_empresas = Œº_educaci√≥n (no hay diferencia en satisfacci√≥n)\")\n",
    "print(\"H‚ÇÅ: Œº_empresas ‚â† Œº_educaci√≥n (hay diferencia en satisfacci√≥n)\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "empresas = df[df['Giro'] == 'Empresa']['D_1'].dropna()\n",
    "educacion = df[df['Giro'] == 'Educaci√≥n']['D_1'].dropna()\n",
    "\n",
    "if len(empresas) > 5 and len(educacion) > 5:\n",
    "    result_t = t_test_analysis(empresas, educacion, 'Empresas', 'Educaci√≥n', 'D_1')\n",
    "    \n",
    "    print(f\"\\nResultados:\")\n",
    "    print(f\"   Empresas: M = {result_t['mean1']:.2f}, n = {result_t['n1']}\")\n",
    "    print(f\"   Educaci√≥n: M = {result_t['mean2']:.2f}, n = {result_t['n2']}\")\n",
    "    print(f\"   t = {result_t['t_stat']:.3f}\")\n",
    "    print(f\"   p-value = {result_t['p_value']:.4f}\")\n",
    "    print(f\"   Cohen's d = {result_t['cohens_d']:.3f} (tama√±o del efecto)\")\n",
    "    \n",
    "    effect_size = \"peque√±o\" if abs(result_t['cohens_d']) < 0.5 else \"mediano\" if abs(result_t['cohens_d']) < 0.8 else \"grande\"\n",
    "    \n",
    "    if result_t['p_value'] < 0.05:\n",
    "        print(f\"\\n‚úÖ CONCLUSI√ìN: Diferencia SIGNIFICATIVA (p < 0.05)\")\n",
    "        print(f\"   Efecto {effect_size}. {'Empresas' if result_t['mean1'] > result_t['mean2'] else 'Educaci√≥n'} tiene mayor satisfacci√≥n.\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå CONCLUSI√ìN: NO hay diferencia significativa (p >= 0.05)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prueba t: Nuevos vs Veteranos\n",
    "print(\"\\nüî¨ PRUEBA T: Satisfacci√≥n de Benefactores Nuevos vs Veteranos\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "nuevos = df[df['antiguedad_grupo'] == 'Nuevo']['D_1'].dropna()\n",
    "veteranos = df[df['antiguedad_grupo'] == 'Veterano']['D_1'].dropna()\n",
    "\n",
    "if len(nuevos) > 5 and len(veteranos) > 5:\n",
    "    result_t2 = t_test_analysis(nuevos, veteranos, 'Nuevos', 'Veteranos', 'D_1')\n",
    "    \n",
    "    print(f\"   Nuevos: M = {result_t2['mean1']:.2f}, n = {result_t2['n1']}\")\n",
    "    print(f\"   Veteranos: M = {result_t2['mean2']:.2f}, n = {result_t2['n2']}\")\n",
    "    print(f\"   t = {result_t2['t_stat']:.3f}, p-value = {result_t2['p_value']:.4f}\")\n",
    "    print(f\"   Cohen's d = {result_t2['cohens_d']:.3f}\")\n",
    "    print(f\"   {'‚úÖ Significativo' if result_t2['p_value'] < 0.05 else '‚ùå No significativo'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prueba t: Promotores vs Detractores en Score SERVQUAL\n",
    "print(\"\\nüî¨ PRUEBA T: Score SERVQUAL de Promotores vs Detractores\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "promotores_servqual = df[df['nps_categoria'] == 'Promotor']['score_servqual_total'].dropna()\n",
    "detractores_servqual = df[df['nps_categoria'] == 'Detractor']['score_servqual_total'].dropna()\n",
    "\n",
    "if len(promotores_servqual) > 5 and len(detractores_servqual) > 5:\n",
    "    result_t3 = t_test_analysis(promotores_servqual, detractores_servqual, 'Promotores', 'Detractores', 'SERVQUAL')\n",
    "    \n",
    "    print(f\"   Promotores: M = {result_t3['mean1']:.2f}, n = {result_t3['n1']}\")\n",
    "    print(f\"   Detractores: M = {result_t3['mean2']:.2f}, n = {result_t3['n2']}\")\n",
    "    print(f\"   t = {result_t3['t_stat']:.3f}, p-value = {result_t3['p_value']:.6f}\")\n",
    "    print(f\"   Cohen's d = {result_t3['cohens_d']:.3f}\")\n",
    "    \n",
    "    if result_t3['p_value'] < 0.05:\n",
    "        print(f\"\\nüí° INSIGHT: Los promotores perciben significativamente mejor calidad de servicio\")\n",
    "        print(f\"   Gap de {result_t3['mean1'] - result_t3['mean2']:.2f} puntos en escala SERVQUAL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 ANOVA - Comparaci√≥n de M√∫ltiples Grupos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOVA: Satisfacci√≥n por Tipo de Organizaci√≥n (Giro)\n",
    "print(\"\\nüî¨ ANOVA: Satisfacci√≥n por Tipo de Organizaci√≥n\")\n",
    "print(\"=\"*70)\n",
    "print(\"H‚ÇÄ: Œº‚ÇÅ = Œº‚ÇÇ = ... = Œº‚Çñ (todas las medias son iguales)\")\n",
    "print(\"H‚ÇÅ: Al menos una media es diferente\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Preparar grupos\n",
    "grupos = [df[df['Giro'] == giro]['D_1'].dropna() for giro in df['Giro'].unique()]\n",
    "grupos = [g for g in grupos if len(g) >= 5]  # Solo grupos con n >= 5\n",
    "\n",
    "if len(grupos) >= 2:\n",
    "    f_stat, p_value = f_oneway(*grupos)\n",
    "    \n",
    "    # Calcular eta-squared (tama√±o del efecto)\n",
    "    df_anova = df[['Giro', 'D_1']].dropna()\n",
    "    ss_between = sum(len(g) * (g.mean() - df_anova['D_1'].mean())**2 for g in grupos)\n",
    "    ss_total = sum((df_anova['D_1'] - df_anova['D_1'].mean())**2)\n",
    "    eta_squared = ss_between / ss_total if ss_total > 0 else 0\n",
    "    \n",
    "    print(f\"\\nResultados:\")\n",
    "    print(f\"   F = {f_stat:.3f}\")\n",
    "    print(f\"   p-value = {p_value:.4f}\")\n",
    "    print(f\"   Œ∑¬≤ = {eta_squared:.3f} (tama√±o del efecto)\")\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        print(f\"\\n‚úÖ CONCLUSI√ìN: Existen diferencias SIGNIFICATIVAS entre grupos\")\n",
    "        print(f\"   Se recomienda an√°lisis post-hoc para identificar qu√© grupos difieren.\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå CONCLUSI√ìN: NO hay diferencias significativas entre grupos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-hoc Tukey HSD (si ANOVA es significativo)\n",
    "if p_value < 0.05:\n",
    "    print(\"\\nüìä AN√ÅLISIS POST-HOC: Tukey HSD\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    df_tukey = df[['Giro', 'D_1']].dropna()\n",
    "    tukey = pairwise_tukeyhsd(df_tukey['D_1'], df_tukey['Giro'], alpha=0.05)\n",
    "    print(tukey)\n",
    "    \n",
    "    # Identificar diferencias significativas\n",
    "    print(\"\\nüí° Pares con diferencias significativas:\")\n",
    "    tukey_df = pd.DataFrame(data=tukey._results_table.data[1:], columns=tukey._results_table.data[0])\n",
    "    sig_pairs = tukey_df[tukey_df['reject'] == True]\n",
    "    if len(sig_pairs) > 0:\n",
    "        for _, row in sig_pairs.iterrows():\n",
    "            print(f\"   {row['group1']} vs {row['group2']}: diferencia = {row['meandiff']:.2f}\")\n",
    "    else:\n",
    "        print(\"   No se encontraron diferencias significativas entre pares espec√≠ficos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n ANOVA - Boxplot por grupo\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Ordenar por media\n",
    "orden = df.groupby('Giro')['D_1'].mean().sort_values(ascending=False).index\n",
    "\n",
    "df.boxplot(column='D_1', by='Giro', ax=ax, positions=range(len(orden)))\n",
    "ax.set_xticklabels(orden, rotation=45, ha='right')\n",
    "ax.axhline(y=df['D_1'].mean(), color='red', linestyle='--', label=f'Media general: {df[\"D_1\"].mean():.1f}')\n",
    "ax.set_xlabel('Tipo de Organizaci√≥n')\n",
    "ax.set_ylabel('Satisfacci√≥n (1-10)')\n",
    "ax.set_title('Distribuci√≥n de Satisfacci√≥n por Tipo de Organizaci√≥n', fontweight='bold')\n",
    "ax.legend()\n",
    "plt.suptitle('')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOVA: NPS por Antig√ºedad\n",
    "print(\"\\nüî¨ ANOVA: NPS por Antig√ºedad del Benefactor\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "df_antig = df.dropna(subset=['antiguedad_grupo', 'NPS'])\n",
    "grupos_antig = [df_antig[df_antig['antiguedad_grupo'] == g]['NPS'] for g in ['Nuevo', 'Establecido', 'Veterano']]\n",
    "grupos_antig = [g for g in grupos_antig if len(g) >= 5]\n",
    "\n",
    "if len(grupos_antig) >= 2:\n",
    "    f_stat2, p_value2 = f_oneway(*grupos_antig)\n",
    "    print(f\"   F = {f_stat2:.3f}, p-value = {p_value2:.4f}\")\n",
    "    print(f\"   {'‚úÖ Significativo' if p_value2 < 0.05 else '‚ùå No significativo'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 4. REGRESI√ìN LINEAL M√öLTIPLE\n",
    "\n",
    "## 4.1 Modelo: Predecir NPS con Dimensiones SERVQUAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos para regresi√≥n\n",
    "df_reg = df[vars_scores + ['NPS', 'A√ëOS']].dropna()\n",
    "\n",
    "X = df_reg[vars_scores]\n",
    "y = df_reg['NPS']\n",
    "\n",
    "# Agregar constante\n",
    "X_const = sm.add_constant(X)\n",
    "\n",
    "# Ajustar modelo OLS\n",
    "modelo = sm.OLS(y, X_const).fit()\n",
    "\n",
    "print(\"\\nüìà REGRESI√ìN LINEAL M√öLTIPLE: Predicci√≥n de NPS\")\n",
    "print(\"=\"*70)\n",
    "print(modelo.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretaci√≥n del modelo\n",
    "print(\"\\nüí° INTERPRETACI√ìN DEL MODELO DE REGRESI√ìN\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüìä Bondad de ajuste:\")\n",
    "print(f\"   R¬≤ = {modelo.rsquared:.3f} ({modelo.rsquared*100:.1f}% de varianza explicada)\")\n",
    "print(f\"   R¬≤ ajustado = {modelo.rsquared_adj:.3f}\")\n",
    "print(f\"   F-estad√≠stico = {modelo.fvalue:.2f} (p = {modelo.f_pvalue:.4f})\")\n",
    "\n",
    "print(f\"\\nüìã Coeficientes (impacto en NPS):\")\n",
    "for var in vars_scores:\n",
    "    coef = modelo.params[var]\n",
    "    p_val = modelo.pvalues[var]\n",
    "    sig = \"***\" if p_val < 0.001 else \"**\" if p_val < 0.01 else \"*\" if p_val < 0.05 else \"\"\n",
    "    print(f\"   {var.replace('score_', ''):15s}: Œ≤ = {coef:+.3f} (p = {p_val:.4f}) {sig}\")\n",
    "\n",
    "# Variable m√°s importante\n",
    "coefs_abs = modelo.params[vars_scores].abs()\n",
    "var_mas_importante = coefs_abs.idxmax()\n",
    "print(f\"\\nüéØ VARIABLE M√ÅS IMPORTANTE: {var_mas_importante.replace('score_', '').upper()}\")\n",
    "print(f\"   Un aumento de 1 punto en {var_mas_importante.replace('score_', '')} se asocia con\")\n",
    "print(f\"   un cambio de {modelo.params[var_mas_importante]:+.2f} puntos en NPS.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n de coeficientes\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "coefs = modelo.params[vars_scores].sort_values()\n",
    "colors = ['#27ae60' if c > 0 else '#e74c3c' for c in coefs.values]\n",
    "\n",
    "bars = ax.barh([s.replace('score_', '').capitalize() for s in coefs.index], \n",
    "               coefs.values, color=colors)\n",
    "ax.axvline(x=0, color='black', linewidth=0.5)\n",
    "\n",
    "for bar, val, var in zip(bars, coefs.values, coefs.index):\n",
    "    p_val = modelo.pvalues[var]\n",
    "    sig = \"*\" if p_val < 0.05 else \"\"\n",
    "    ax.text(val + 0.05 if val > 0 else val - 0.15, bar.get_y() + bar.get_height()/2, \n",
    "            f'{val:.2f}{sig}', va='center', fontsize=11)\n",
    "\n",
    "ax.set_xlabel('Coeficiente de Regresi√≥n')\n",
    "ax.set_title('Impacto de cada Dimensi√≥n SERVQUAL en el NPS', fontweight='bold', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar multicolinealidad (VIF)\n",
    "print(\"\\nüîç DIAGN√ìSTICO DE MULTICOLINEALIDAD (VIF)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data['Variable'] = X.columns\n",
    "vif_data['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "print(vif_data.to_string(index=False))\n",
    "print(\"\\nInterpretaci√≥n: VIF > 5 indica multicolinealidad problem√°tica\")\n",
    "\n",
    "if any(vif_data['VIF'] > 5):\n",
    "    print(\"‚ö†Ô∏è ADVERTENCIA: Algunas variables tienen alta multicolinealidad\")\n",
    "else:\n",
    "    print(\"‚úÖ No hay problemas de multicolinealidad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 2: Predecir Satisfacci√≥n (D_1)\n",
    "print(\"\\nüìà REGRESI√ìN LINEAL: Predicci√≥n de Satisfacci√≥n (D_1)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "df_reg2 = df[vars_scores + ['D_1']].dropna()\n",
    "X2 = df_reg2[vars_scores]\n",
    "y2 = df_reg2['D_1']\n",
    "X2_const = sm.add_constant(X2)\n",
    "\n",
    "modelo2 = sm.OLS(y2, X2_const).fit()\n",
    "\n",
    "print(f\"R¬≤ = {modelo2.rsquared:.3f} ({modelo2.rsquared*100:.1f}% varianza explicada)\")\n",
    "print(f\"\\nCoeficientes significativos:\")\n",
    "for var in vars_scores:\n",
    "    if modelo2.pvalues[var] < 0.05:\n",
    "        print(f\"   {var.replace('score_', ''):15s}: Œ≤ = {modelo2.params[var]:+.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 5. RESUMEN DE HALLAZGOS Y RECOMENDACIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar resumen ejecutivo\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMEN EJECUTIVO - DIAGN√ìSTICO DE CALIDAD DE SERVICIO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìä 1. M√âTRICAS GENERALES\")\n",
    "print(f\"   ‚Ä¢ NPS Score: {nps_score:.0f} {'(Bueno)' if nps_score > 0 else '(Necesita mejora)'}\")\n",
    "print(f\"   ‚Ä¢ Satisfacci√≥n: {df['D_1'].mean():.1f}/10\")\n",
    "print(f\"   ‚Ä¢ Score SERVQUAL: {df['score_servqual_total'].mean():.2f}/5\")\n",
    "\n",
    "print(\"\\nüî¨ 2. HALLAZGOS ESTAD√çSTICOS\")\n",
    "\n",
    "# Correlaci√≥n m√°s alta con NPS\n",
    "corr_max = corr_df.iloc[0]\n",
    "print(f\"   ‚Ä¢ La dimensi√≥n '{corr_max['Variable'].replace('score_', '')}' tiene la mayor correlaci√≥n con NPS (r={corr_max['Correlaci√≥n']:.2f})\")\n",
    "\n",
    "# Chi-cuadrada\n",
    "if result['significativo']:\n",
    "    print(f\"   ‚Ä¢ Existe asociaci√≥n significativa entre tipo de organizaci√≥n y categor√≠a NPS\")\n",
    "else:\n",
    "    print(f\"   ‚Ä¢ No hay asociaci√≥n significativa entre tipo de organizaci√≥n y NPS\")\n",
    "\n",
    "# Regresi√≥n\n",
    "print(f\"   ‚Ä¢ El modelo SERVQUAL explica {modelo.rsquared*100:.0f}% de la varianza del NPS\")\n",
    "print(f\"   ‚Ä¢ Variable m√°s predictiva: {var_mas_importante.replace('score_', '').upper()}\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è 3. √ÅREAS DE OPORTUNIDAD\")\n",
    "dim_scores = {dim: df[f'score_{dim}'].mean() for dim in ['tangibles', 'fiabilidad', 'responsiveness', 'empatia']}\n",
    "dim_min = min(dim_scores, key=dim_scores.get)\n",
    "print(f\"   ‚Ä¢ Dimensi√≥n con menor score: {dim_min.upper()} ({dim_scores[dim_min]:.2f})\")\n",
    "print(f\"   ‚Ä¢ Segmento con menor satisfacci√≥n: {giro_peor}\")\n",
    "print(f\"   ‚Ä¢ {len(detractores)} benefactores detractores ({len(detractores)/len(df)*100:.1f}%) requieren atenci√≥n\")\n",
    "\n",
    "print(\"\\nüí° 4. RECOMENDACIONES\")\n",
    "print(f\"   1. Priorizar mejoras en la dimensi√≥n '{dim_min.upper()}' - mayor impacto potencial\")\n",
    "print(f\"   2. Dise√±ar estrategia espec√≠fica para '{giro_peor}'\")\n",
    "print(f\"   3. Implementar programa de recuperaci√≥n para detractores\")\n",
    "print(f\"   4. Capacitar promotores en las competencias de '{var_mas_importante.replace('score_', '')}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar resultados clave para el dashboard\n",
    "resultados = {\n",
    "    'nps_score': nps_score,\n",
    "    'satisfaccion_promedio': df['D_1'].mean(),\n",
    "    'calidad_promedio': df['C_1'].mean(),\n",
    "    'servqual_total': df['score_servqual_total'].mean(),\n",
    "    'dimension_mas_correlacion': corr_max['Variable'].replace('score_', ''),\n",
    "    'correlacion_max': corr_max['Correlaci√≥n'],\n",
    "    'r_squared_modelo': modelo.rsquared,\n",
    "    'variable_mas_importante': var_mas_importante.replace('score_', ''),\n",
    "    'dimension_menor_score': dim_min,\n",
    "    'giro_menor_satisfaccion': giro_peor,\n",
    "    'n_detractores': len(detractores),\n",
    "    'pct_detractores': len(detractores)/len(df)*100\n",
    "}\n",
    "\n",
    "print(\"\\nüìÅ Resultados guardados para el dashboard:\")\n",
    "for k, v in resultados.items():\n",
    "    print(f\"   {k}: {v}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}