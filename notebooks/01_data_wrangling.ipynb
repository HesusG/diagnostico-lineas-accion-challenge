{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling y Enriquecimiento - Encuesta Fundación Teletón\n",
    "\n",
    "Este notebook realiza el procesamiento, limpieza y enriquecimiento de los datos de la encuesta de satisfacción de Fundación Teletón, basada en el modelo **SERVQUAL**.\n",
    "\n",
    "## Dimensiones SERVQUAL en el Dataset\n",
    "- **Tangibles (AT)**: Apariencia física, procedimientos y documentación\n",
    "- **Fiabilidad (FI)**: Cumplimiento de promesas, conocimiento, información clara\n",
    "- **Responsiveness (R)**: Rapidez, disposición a ayudar, flexibilidad\n",
    "- **Empatía (E)**: Comprensión, dedicación de tiempo, atención personalizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos originales\n",
    "df = pd.read_csv('../data/teleton-non-excel.csv', encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Dimensiones del dataset: {df.shape[0]} registros x {df.shape[1]} columnas\")\n",
    "print(f\"\\nColumnas:\\n{df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vista previa de los datos\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Información del dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores nulos por columna\n",
    "nulos = df.isnull().sum()\n",
    "print(\"Valores nulos por columna:\")\n",
    "print(nulos[nulos > 0] if nulos.sum() > 0 else \"No hay valores nulos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Limpieza y Tipos de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear copia para trabajar\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Renombrar columnas para consistencia\n",
    "df_clean = df_clean.rename(columns={\n",
    "    'R_12': 'NPS',  # Variable de recomendación (Net Promoter Score)\n",
    "    'Info': 'INFO',\n",
    "    'Años': 'AÑOS'\n",
    "})\n",
    "\n",
    "print(\"Columnas renombradas:\")\n",
    "print(df_clean.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir timestamp a datetime\n",
    "df_clean['timestamp'] = pd.to_datetime(df_clean['timestamp'], format='%m/%d/%Y %H:%M:%S')\n",
    "\n",
    "print(f\"Rango de fechas: {df_clean['timestamp'].min()} a {df_clean['timestamp'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir variables por tipo\n",
    "vars_servqual = ['AT_1', 'AT_2', 'FI_1', 'FI_2', 'FI_3', 'R_1', 'R_2', 'R_3', 'E_1', 'E_2', 'E_3', 'E_4']\n",
    "vars_outcome_5 = ['C_1']  # Escala 1-5\n",
    "vars_outcome_10 = ['D_1', 'NPS', 'INFO']  # Escala 1-10\n",
    "vars_categoricas = ['Giro', 'Puesto', 'Estado']\n",
    "\n",
    "print(f\"Variables SERVQUAL (escala 1-5): {len(vars_servqual)} variables\")\n",
    "print(f\"Variables Outcome escala 1-5: {vars_outcome_5}\")\n",
    "print(f\"Variables Outcome escala 1-10: {vars_outcome_10}\")\n",
    "print(f\"Variables Categóricas: {vars_categoricas}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir variables numéricas a tipos óptimos\n",
    "# Variables SERVQUAL y C_1 (escala 1-5) a Int8 (permite NaN)\n",
    "for col in vars_servqual + vars_outcome_5:\n",
    "    df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce').astype('Int8')\n",
    "\n",
    "# Variables outcome escala 1-10 a Int8\n",
    "for col in vars_outcome_10:\n",
    "    df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce').astype('Int8')\n",
    "\n",
    "# Años como Int16 (puede haber valores > 127)\n",
    "df_clean['AÑOS'] = pd.to_numeric(df_clean['AÑOS'], errors='coerce').astype('Int16')\n",
    "\n",
    "print(\"Tipos de datos actualizados para variables numéricas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir variables categóricas\n",
    "for col in vars_categoricas:\n",
    "    df_clean[col] = df_clean[col].astype('category')\n",
    "\n",
    "# Verificar categorías únicas\n",
    "for col in vars_categoricas:\n",
    "    print(f\"\\n{col}: {df_clean[col].nunique()} categorías\")\n",
    "    print(df_clean[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar tipos de datos finales\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas descriptivas de variables numéricas\n",
    "df_clean[vars_servqual + vars_outcome_5 + vars_outcome_10 + ['AÑOS']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Variables Temporales Derivadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer componentes temporales\n",
    "df_clean['fecha'] = df_clean['timestamp'].dt.date\n",
    "df_clean['mes'] = df_clean['timestamp'].dt.month\n",
    "df_clean['dia_semana'] = df_clean['timestamp'].dt.day_name()\n",
    "df_clean['dia_semana_num'] = df_clean['timestamp'].dt.dayofweek\n",
    "df_clean['hora'] = df_clean['timestamp'].dt.hour\n",
    "\n",
    "# Crear variable de turno\n",
    "def clasificar_turno(hora):\n",
    "    if 6 <= hora < 12:\n",
    "        return 'Mañana'\n",
    "    elif 12 <= hora < 18:\n",
    "        return 'Tarde'\n",
    "    else:\n",
    "        return 'Noche'\n",
    "\n",
    "df_clean['turno'] = df_clean['hora'].apply(clasificar_turno).astype('category')\n",
    "\n",
    "print(\"Variables temporales creadas:\")\n",
    "print(df_clean[['timestamp', 'fecha', 'mes', 'dia_semana', 'hora', 'turno']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribución de respuestas por turno\n",
    "print(\"Respuestas por turno:\")\n",
    "print(df_clean['turno'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribución por día de la semana\n",
    "print(\"\\nRespuestas por día de la semana:\")\n",
    "dias_orden = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "print(df_clean['dia_semana'].value_counts().reindex(dias_orden))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Scores SERVQUAL Agregados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir ítems por dimensión SERVQUAL\n",
    "dimensiones_servqual = {\n",
    "    'tangibles': ['AT_1', 'AT_2'],\n",
    "    'fiabilidad': ['FI_1', 'FI_2', 'FI_3'],\n",
    "    'responsiveness': ['R_1', 'R_2', 'R_3'],\n",
    "    'empatia': ['E_1', 'E_2', 'E_3', 'E_4']\n",
    "}\n",
    "\n",
    "# Calcular score promedio por dimensión\n",
    "for dimension, items in dimensiones_servqual.items():\n",
    "    df_clean[f'score_{dimension}'] = df_clean[items].mean(axis=1).round(2)\n",
    "    print(f\"Score {dimension}: promedio de {items}\")\n",
    "\n",
    "# Score SERVQUAL total (promedio de las 4 dimensiones)\n",
    "scores_dimensiones = [f'score_{d}' for d in dimensiones_servqual.keys()]\n",
    "df_clean['score_servqual_total'] = df_clean[scores_dimensiones].mean(axis=1).round(2)\n",
    "\n",
    "print(f\"\\nScore SERVQUAL total: promedio de {scores_dimensiones}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar scores calculados\n",
    "df_clean[['score_tangibles', 'score_fiabilidad', 'score_responsiveness', 'score_empatia', 'score_servqual_total']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Variables Discretas / Categóricas Derivadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categoría NPS (Net Promoter Score)\n",
    "# Detractores: 1-6, Pasivos: 7-8, Promotores: 9-10\n",
    "def clasificar_nps(valor):\n",
    "    if pd.isna(valor):\n",
    "        return np.nan\n",
    "    elif valor <= 6:\n",
    "        return 'Detractor'\n",
    "    elif valor <= 8:\n",
    "        return 'Pasivo'\n",
    "    else:\n",
    "        return 'Promotor'\n",
    "\n",
    "df_clean['nps_categoria'] = df_clean['NPS'].apply(clasificar_nps).astype('category')\n",
    "\n",
    "print(\"Distribución NPS:\")\n",
    "print(df_clean['nps_categoria'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular NPS Score oficial\n",
    "# NPS = % Promotores - % Detractores\n",
    "nps_counts = df_clean['nps_categoria'].value_counts(normalize=True) * 100\n",
    "nps_score = nps_counts.get('Promotor', 0) - nps_counts.get('Detractor', 0)\n",
    "\n",
    "print(f\"\\nNPS Score de Fundación Teletón: {nps_score:.1f}\")\n",
    "print(f\"  - Promotores: {nps_counts.get('Promotor', 0):.1f}%\")\n",
    "print(f\"  - Pasivos: {nps_counts.get('Pasivo', 0):.1f}%\")\n",
    "print(f\"  - Detractores: {nps_counts.get('Detractor', 0):.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nivel de satisfacción (D_1)\n",
    "# Bajo: 1-4, Medio: 5-7, Alto: 8-10\n",
    "def clasificar_satisfaccion(valor):\n",
    "    if pd.isna(valor):\n",
    "        return np.nan\n",
    "    elif valor <= 4:\n",
    "        return 'Bajo'\n",
    "    elif valor <= 7:\n",
    "        return 'Medio'\n",
    "    else:\n",
    "        return 'Alto'\n",
    "\n",
    "df_clean['satisfaccion_nivel'] = df_clean['D_1'].apply(clasificar_satisfaccion).astype('category')\n",
    "\n",
    "print(\"Distribución de Satisfacción:\")\n",
    "print(df_clean['satisfaccion_nivel'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nivel de calidad percibida (C_1)\n",
    "# Deficiente: 1-2, Regular: 3, Bueno: 4-5\n",
    "def clasificar_calidad(valor):\n",
    "    if pd.isna(valor):\n",
    "        return np.nan\n",
    "    elif valor <= 2:\n",
    "        return 'Deficiente'\n",
    "    elif valor == 3:\n",
    "        return 'Regular'\n",
    "    else:\n",
    "        return 'Bueno'\n",
    "\n",
    "df_clean['calidad_nivel'] = df_clean['C_1'].apply(clasificar_calidad).astype('category')\n",
    "\n",
    "print(\"Distribución de Calidad Percibida:\")\n",
    "print(df_clean['calidad_nivel'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antigüedad como benefactor\n",
    "# Nuevo: 1-2 años, Establecido: 3-5 años, Veterano: 6+ años\n",
    "def clasificar_antiguedad(valor):\n",
    "    if pd.isna(valor):\n",
    "        return np.nan\n",
    "    elif valor <= 2:\n",
    "        return 'Nuevo'\n",
    "    elif valor <= 5:\n",
    "        return 'Establecido'\n",
    "    else:\n",
    "        return 'Veterano'\n",
    "\n",
    "df_clean['antiguedad_grupo'] = df_clean['AÑOS'].apply(clasificar_antiguedad).astype('category')\n",
    "\n",
    "print(\"Distribución por Antigüedad:\")\n",
    "print(df_clean['antiguedad_grupo'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nivel de información percibida (INFO)\n",
    "# Bajo: 1-4, Medio: 5-7, Alto: 8-10\n",
    "def clasificar_info(valor):\n",
    "    if pd.isna(valor):\n",
    "        return np.nan\n",
    "    elif valor <= 4:\n",
    "        return 'Desinformado'\n",
    "    elif valor <= 7:\n",
    "        return 'Parcialmente informado'\n",
    "    else:\n",
    "        return 'Bien informado'\n",
    "\n",
    "df_clean['info_nivel'] = df_clean['INFO'].apply(clasificar_info).astype('category')\n",
    "\n",
    "print(\"Distribución de Nivel de Información:\")\n",
    "print(df_clean['info_nivel'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Enriquecimiento Geográfico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeo de estados a regiones geográficas de México\n",
    "regiones_mexico = {\n",
    "    'Aguascalientes': 'Centro-Norte',\n",
    "    'Baja California': 'Noroeste',\n",
    "    'Baja California Sur': 'Noroeste',\n",
    "    'Campeche': 'Sureste',\n",
    "    'Chiapas': 'Sureste',\n",
    "    'Chihuahua': 'Norte',\n",
    "    'Ciudad de México': 'Centro',\n",
    "    'Coahuila': 'Norte',\n",
    "    'Colima': 'Occidente',\n",
    "    'Durango': 'Norte',\n",
    "    'Estado de México': 'Centro',\n",
    "    'Guanajuato': 'Bajío',\n",
    "    'Guerrero': 'Sur',\n",
    "    'Hidalgo': 'Centro',\n",
    "    'Jalisco': 'Occidente',\n",
    "    'Michoacán': 'Occidente',\n",
    "    'Morelos': 'Centro',\n",
    "    'Nayarit': 'Occidente',\n",
    "    'Nuevo León': 'Noreste',\n",
    "    'Oaxaca': 'Sur',\n",
    "    'Puebla': 'Centro',\n",
    "    'Querétaro': 'Bajío',\n",
    "    'Quintana Roo': 'Sureste',\n",
    "    'San Luis Potosí': 'Centro-Norte',\n",
    "    'Sinaloa': 'Noroeste',\n",
    "    'Sonora': 'Noroeste',\n",
    "    'Tabasco': 'Sureste',\n",
    "    'Tamaulipas': 'Noreste',\n",
    "    'Tlaxcala': 'Centro',\n",
    "    'Veracruz': 'Golfo',\n",
    "    'Yucatán': 'Sureste',\n",
    "    'Zacatecas': 'Centro-Norte'\n",
    "}\n",
    "\n",
    "# Limpiar estados con valores múltiples (ej: \"Ciudad de México, Morelos\")\n",
    "df_clean['Estado_limpio'] = df_clean['Estado'].astype(str).apply(\n",
    "    lambda x: x.split(',')[0].strip() if ',' in x else x\n",
    ")\n",
    "\n",
    "# Asignar región\n",
    "df_clean['region'] = df_clean['Estado_limpio'].map(regiones_mexico).astype('category')\n",
    "\n",
    "print(\"Estados únicos en el dataset:\")\n",
    "print(df_clean['Estado_limpio'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribución por región\n",
    "print(\"\\nDistribución por Región:\")\n",
    "print(df_clean['region'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de población por estado (INEGI 2020 - en millones)\n",
    "poblacion_estados = {\n",
    "    'Aguascalientes': 1.43,\n",
    "    'Baja California': 3.77,\n",
    "    'Baja California Sur': 0.80,\n",
    "    'Campeche': 0.93,\n",
    "    'Chiapas': 5.54,\n",
    "    'Chihuahua': 3.74,\n",
    "    'Ciudad de México': 9.21,\n",
    "    'Coahuila': 3.15,\n",
    "    'Colima': 0.73,\n",
    "    'Durango': 1.83,\n",
    "    'Estado de México': 16.99,\n",
    "    'Guanajuato': 6.17,\n",
    "    'Guerrero': 3.54,\n",
    "    'Hidalgo': 3.08,\n",
    "    'Jalisco': 8.35,\n",
    "    'Michoacán': 4.75,\n",
    "    'Morelos': 1.97,\n",
    "    'Nayarit': 1.29,\n",
    "    'Nuevo León': 5.78,\n",
    "    'Oaxaca': 4.13,\n",
    "    'Puebla': 6.58,\n",
    "    'Querétaro': 2.37,\n",
    "    'Quintana Roo': 1.86,\n",
    "    'San Luis Potosí': 2.82,\n",
    "    'Sinaloa': 3.03,\n",
    "    'Sonora': 2.94,\n",
    "    'Tabasco': 2.40,\n",
    "    'Tamaulipas': 3.53,\n",
    "    'Tlaxcala': 1.34,\n",
    "    'Veracruz': 8.06,\n",
    "    'Yucatán': 2.32,\n",
    "    'Zacatecas': 1.62\n",
    "}\n",
    "\n",
    "# PIB per cápita por estado (miles de pesos, 2020)\n",
    "pib_per_capita_estados = {\n",
    "    'Aguascalientes': 198,\n",
    "    'Baja California': 214,\n",
    "    'Baja California Sur': 247,\n",
    "    'Campeche': 442,\n",
    "    'Chiapas': 58,\n",
    "    'Chihuahua': 218,\n",
    "    'Ciudad de México': 394,\n",
    "    'Coahuila': 263,\n",
    "    'Colima': 173,\n",
    "    'Durango': 142,\n",
    "    'Estado de México': 114,\n",
    "    'Guanajuato': 157,\n",
    "    'Guerrero': 79,\n",
    "    'Hidalgo': 115,\n",
    "    'Jalisco': 183,\n",
    "    'Michoacán': 107,\n",
    "    'Morelos': 108,\n",
    "    'Nayarit': 109,\n",
    "    'Nuevo León': 310,\n",
    "    'Oaxaca': 73,\n",
    "    'Puebla': 113,\n",
    "    'Querétaro': 250,\n",
    "    'Quintana Roo': 211,\n",
    "    'San Luis Potosí': 161,\n",
    "    'Sinaloa': 151,\n",
    "    'Sonora': 219,\n",
    "    'Tabasco': 180,\n",
    "    'Tamaulipas': 182,\n",
    "    'Tlaxcala': 80,\n",
    "    'Veracruz': 118,\n",
    "    'Yucatán': 149,\n",
    "    'Zacatecas': 118\n",
    "}\n",
    "\n",
    "# Agregar datos al dataframe\n",
    "df_clean['poblacion_millones'] = df_clean['Estado_limpio'].map(poblacion_estados)\n",
    "df_clean['pib_per_capita_miles'] = df_clean['Estado_limpio'].map(pib_per_capita_estados)\n",
    "\n",
    "print(\"Datos geográficos agregados:\")\n",
    "df_clean[['Estado_limpio', 'region', 'poblacion_millones', 'pib_per_capita_miles']].drop_duplicates().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular respuestas por millón de habitantes por estado\n",
    "respuestas_por_estado = df_clean.groupby('Estado_limpio').size().reset_index(name='n_respuestas')\n",
    "respuestas_por_estado['poblacion'] = respuestas_por_estado['Estado_limpio'].map(poblacion_estados)\n",
    "respuestas_por_estado['respuestas_por_millon'] = (respuestas_por_estado['n_respuestas'] / respuestas_por_estado['poblacion']).round(2)\n",
    "\n",
    "print(\"Densidad de respuestas por estado (por millón de habitantes):\")\n",
    "print(respuestas_por_estado.sort_values('respuestas_por_millon', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clasificar nivel económico del estado\n",
    "def clasificar_nivel_economico(pib):\n",
    "    if pd.isna(pib):\n",
    "        return np.nan\n",
    "    elif pib < 120:\n",
    "        return 'Bajo'\n",
    "    elif pib < 200:\n",
    "        return 'Medio'\n",
    "    else:\n",
    "        return 'Alto'\n",
    "\n",
    "df_clean['nivel_economico_estado'] = df_clean['pib_per_capita_miles'].apply(clasificar_nivel_economico).astype('category')\n",
    "\n",
    "print(\"\\nDistribución por nivel económico del estado:\")\n",
    "print(df_clean['nivel_economico_estado'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Coordenadas de centroides de estados de México (lat, long)\ncoordenadas_estados = {\n    'Aguascalientes': (21.8853, -102.2916),\n    'Baja California': (30.8406, -115.2838),\n    'Baja California Sur': (26.0444, -111.6661),\n    'Campeche': (19.8301, -90.5349),\n    'Chiapas': (16.7569, -93.1292),\n    'Chihuahua': (28.6330, -106.0691),\n    'Ciudad de México': (19.4326, -99.1332),\n    'Coahuila': (27.0587, -101.7068),\n    'Colima': (19.2452, -103.7241),\n    'Durango': (24.0277, -104.6532),\n    'Estado de México': (19.4969, -99.7233),\n    'Guanajuato': (21.0190, -101.2574),\n    'Guerrero': (17.4392, -99.5451),\n    'Hidalgo': (20.0911, -98.7624),\n    'Jalisco': (20.6595, -103.3494),\n    'Michoacán': (19.5665, -101.7068),\n    'Morelos': (18.6813, -99.1013),\n    'Nayarit': (21.7514, -104.8455),\n    'Nuevo León': (25.5922, -99.9962),\n    'Oaxaca': (17.0732, -96.7266),\n    'Puebla': (19.0414, -98.2063),\n    'Querétaro': (20.5888, -100.3899),\n    'Quintana Roo': (19.1817, -88.4791),\n    'San Luis Potosí': (22.1565, -100.9855),\n    'Sinaloa': (24.8091, -107.3940),\n    'Sonora': (29.2972, -110.3309),\n    'Tabasco': (17.8409, -92.6189),\n    'Tamaulipas': (24.2669, -98.8363),\n    'Tlaxcala': (19.3139, -98.2404),\n    'Veracruz': (19.1738, -96.1342),\n    'Yucatán': (20.7099, -89.0943),\n    'Zacatecas': (22.7709, -102.5832)\n}\n\n# Agregar lat y long al dataframe\ndf_clean['lat'] = df_clean['Estado_limpio'].map(lambda x: coordenadas_estados.get(x, (None, None))[0])\ndf_clean['long'] = df_clean['Estado_limpio'].map(lambda x: coordenadas_estados.get(x, (None, None))[1])\n\nprint(\"Coordenadas agregadas:\")\ndf_clean[['Estado_limpio', 'lat', 'long']].drop_duplicates().head(10)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Resumen del Dataset Enriquecido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver todas las columnas del dataset enriquecido\n",
    "print(f\"Dataset enriquecido: {df_clean.shape[0]} registros x {df_clean.shape[1]} columnas\")\n",
    "print(f\"\\nColumnas originales: {df.shape[1]}\")\n",
    "print(f\"Columnas nuevas: {df_clean.shape[1] - df.shape[1]}\")\n",
    "\n",
    "print(\"\\n--- COLUMNAS DEL DATASET ENRIQUECIDO ---\")\n",
    "for i, col in enumerate(df_clean.columns, 1):\n",
    "    print(f\"{i:2d}. {col} ({df_clean[col].dtype})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vista previa del dataset final\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Información del dataset final\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen de variables categóricas derivadas\n",
    "vars_categoricas_nuevas = ['nps_categoria', 'satisfaccion_nivel', 'calidad_nivel', 'antiguedad_grupo', 'info_nivel', 'turno', 'region', 'nivel_economico_estado']\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"RESUMEN DE VARIABLES CATEGÓRICAS DERIVADAS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for var in vars_categoricas_nuevas:\n",
    "    print(f\"\\n>>> {var}\")\n",
    "    print(df_clean[var].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Exportar Dataset Enriquecido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Ordenar columnas de manera lógica\ncolumnas_ordenadas = [\n    # Identificadores temporales\n    'timestamp', 'fecha', 'mes', 'dia_semana', 'dia_semana_num', 'hora', 'turno',\n    # Variables SERVQUAL originales\n    'AT_1', 'AT_2', 'FI_1', 'FI_2', 'FI_3', 'R_1', 'R_2', 'R_3', 'E_1', 'E_2', 'E_3', 'E_4',\n    # Scores SERVQUAL\n    'score_tangibles', 'score_fiabilidad', 'score_responsiveness', 'score_empatia', 'score_servqual_total',\n    # Variables outcome\n    'D_1', 'satisfaccion_nivel', 'NPS', 'nps_categoria', 'C_1', 'calidad_nivel', 'INFO', 'info_nivel',\n    # Variables demográficas\n    'AÑOS', 'antiguedad_grupo', 'Giro', 'Puesto',\n    # Variables geográficas\n    'Estado', 'Estado_limpio', 'region', 'poblacion_millones', 'pib_per_capita_miles', 'nivel_economico_estado',\n    # Coordenadas geográficas\n    'lat', 'long'\n]\n\ndf_final = df_clean[columnas_ordenadas]\n\nprint(f\"Dataset final: {df_final.shape[0]} registros x {df_final.shape[1]} columnas\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar a CSV\n",
    "df_final.to_csv('../data/teleton_enriched.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"Dataset exportado a: ../data/teleton_enriched.csv\")\n",
    "\n",
    "# Exportar a Parquet (más eficiente para análisis)\n",
    "df_final.to_parquet('../data/teleton_enriched.parquet', index=False)\n",
    "print(\"Dataset exportado a: ../data/teleton_enriched.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Diccionario de Variables del Dataset Enriquecido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario_variables = \"\"\"\n",
    "# Diccionario de Variables - Dataset Enriquecido Teletón\n",
    "\n",
    "## Variables Temporales\n",
    "| Variable | Descripción | Tipo |\n",
    "|----------|-------------|------|\n",
    "| timestamp | Fecha y hora de la respuesta | datetime |\n",
    "| fecha | Fecha de la respuesta | date |\n",
    "| mes | Mes de la respuesta (1-12) | int |\n",
    "| dia_semana | Nombre del día de la semana | category |\n",
    "| dia_semana_num | Número del día (0=Lunes, 6=Domingo) | int |\n",
    "| hora | Hora de la respuesta (0-23) | int |\n",
    "| turno | Turno del día (Mañana/Tarde/Noche) | category |\n",
    "\n",
    "## Variables SERVQUAL (escala 1-5)\n",
    "| Variable | Dimensión | Descripción |\n",
    "|----------|-----------|-------------|\n",
    "| AT_1 | Tangibles | Se viste y comporta apropiadamente |\n",
    "| AT_2 | Tangibles | Procedimientos y documentación claros |\n",
    "| FI_1 | Fiabilidad | Cumple con horarios y plazos |\n",
    "| FI_2 | Fiabilidad | Alto nivel de conocimiento |\n",
    "| FI_3 | Fiabilidad | Información correcta y clara |\n",
    "| R_1 | Responsiveness | Responde de forma rápida |\n",
    "| R_2 | Responsiveness | Disposición a ayudar |\n",
    "| R_3 | Responsiveness | Flexibilidad |\n",
    "| E_1 | Empatía | Actitud comprensiva |\n",
    "| E_2 | Empatía | Dedicación de tiempo |\n",
    "| E_3 | Empatía | Entiende y se preocupa |\n",
    "| E_4 | Empatía | Atención personalizada |\n",
    "\n",
    "## Scores SERVQUAL Agregados\n",
    "| Variable | Descripción | Rango |\n",
    "|----------|-------------|-------|\n",
    "| score_tangibles | Promedio de AT_1, AT_2 | 1-5 |\n",
    "| score_fiabilidad | Promedio de FI_1, FI_2, FI_3 | 1-5 |\n",
    "| score_responsiveness | Promedio de R_1, R_2, R_3 | 1-5 |\n",
    "| score_empatia | Promedio de E_1, E_2, E_3, E_4 | 1-5 |\n",
    "| score_servqual_total | Promedio de las 4 dimensiones | 1-5 |\n",
    "\n",
    "## Variables Outcome\n",
    "| Variable | Descripción | Escala |\n",
    "|----------|-------------|--------|\n",
    "| D_1 | Nivel de satisfacción | 1-10 |\n",
    "| satisfaccion_nivel | Categoría de satisfacción | Bajo/Medio/Alto |\n",
    "| NPS | Recomendación (Net Promoter) | 1-10 |\n",
    "| nps_categoria | Categoría NPS | Detractor/Pasivo/Promotor |\n",
    "| C_1 | Calidad percibida | 1-5 |\n",
    "| calidad_nivel | Categoría de calidad | Deficiente/Regular/Bueno |\n",
    "| INFO | Nivel de información | 1-10 |\n",
    "| info_nivel | Categoría de información | Desinformado/Parcialmente/Bien informado |\n",
    "\n",
    "## Variables Demográficas\n",
    "| Variable | Descripción | Tipo |\n",
    "|----------|-------------|------|\n",
    "| AÑOS | Años como benefactor | int |\n",
    "| antiguedad_grupo | Categoría de antigüedad | Nuevo/Establecido/Veterano |\n",
    "| Giro | Tipo de organización | category |\n",
    "| Puesto | Puesto del encuestado | category |\n",
    "\n",
    "## Variables Geográficas\n",
    "| Variable | Descripción | Tipo |\n",
    "|----------|-------------|------|\n",
    "| Estado | Estado original | category |\n",
    "| Estado_limpio | Estado limpio (sin valores múltiples) | string |\n",
    "| region | Región geográfica de México | category |\n",
    "| poblacion_millones | Población del estado (millones) | float |\n",
    "| pib_per_capita_miles | PIB per cápita (miles de pesos) | float |\n",
    "| nivel_economico_estado | Nivel económico del estado | Bajo/Medio/Alto |\n",
    "\"\"\"\n",
    "\n",
    "print(diccionario_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Resumen Ejecutivo\n",
    "\n",
    "Se realizó el procesamiento y enriquecimiento del dataset de encuestas de Fundación Teletón:\n",
    "\n",
    "**Transformaciones realizadas:**\n",
    "1. Conversión de tipos de datos óptimos (int8 para escalas, category para categóricas)\n",
    "2. Creación de variables temporales (turno, día de semana, hora)\n",
    "3. Cálculo de scores SERVQUAL por dimensión y total\n",
    "4. Creación de variables discretas (NPS categoria, nivel satisfacción, etc.)\n",
    "5. Enriquecimiento geográfico (región, población, PIB per cápita)\n",
    "\n",
    "**Dataset final:** 274 registros x 38 columnas\n",
    "\n",
    "**Archivos exportados:**\n",
    "- `teleton_enriched.csv`\n",
    "- `teleton_enriched.parquet`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}